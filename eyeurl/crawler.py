import datetime
import time
import os
import re
from urllib.parse import urljoin
from tqdm import tqdm
import colorama
from playwright.sync_api import sync_playwright

def process_url(url, options, visited_urls=None, level=0, parent_url=None):
    """
    å¤„ç†å•ä¸ªURLï¼Œæˆªå›¾å¹¶å¯é€‰åœ°é€’å½’å¤„ç†å…¶ä¸­çš„é“¾æ¥
    
    Args:
        url: è¦å¤„ç†çš„URL
        options: é€‰é¡¹å­—å…¸
        visited_urls: å·²è®¿é—®URLé›†åˆï¼ˆç”¨äºé¿å…é‡å¤ï¼‰
        level: å½“å‰æ·±åº¦çº§åˆ«
        parent_url: çˆ¶URLï¼ˆç”¨äºæ˜¾ç¤ºå¼•ç”¨å…³ç³»ï¼‰
    
    Returns:
        åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
    """
    if visited_urls is None:
        visited_urls = set()
    
    # é¿å…é‡å¤å¤„ç†ç›¸åŒURL
    url_key = canonicalize_url(url)
    if url_key in visited_urls:
        logger.info(f"{colorama.Fore.YELLOW}âŸ² {url} - å·²å¤„ç†ï¼Œè·³è¿‡{colorama.Style.RESET_ALL}")
        return None
    
    # æˆªæ–­è¿‡é•¿URLä»¥ä¾¿æ˜¾ç¤º
    display_url = truncate_url(url, max_length=80)
    
    # çˆ¶URL æ˜¾ç¤º
    parent_info = ""
    if parent_url:
        parent_display = truncate_url(parent_url, max_length=50)
        parent_info = f"{colorama.Fore.BLUE}â† {parent_display}{colorama.Style.RESET_ALL}"
    
    # ç¼©è¿›å’Œæ·±åº¦æ˜¾ç¤º
    indent = "  " * level
    depth_marker = f"{colorama.Fore.CYAN}[æ·±åº¦:{level}]{colorama.Style.RESET_ALL}"
    
    logger.info(f"{indent}{depth_marker} {colorama.Fore.WHITE}ğŸŒ å¤„ç†: {colorama.Fore.GREEN}{display_url}{colorama.Style.RESET_ALL} {parent_info}")
    
    # åˆ›å»ºç»“æœå­—å…¸
    result = {
        'url': url,
        'referrer': parent_url,
        'timestamp': datetime.datetime.now().isoformat(),
        'depth_level': level
    }
    
    # æ·»åŠ åˆ°å·²è®¿é—®é›†åˆ
    visited_urls.add(url_key)
    
    # åŸºæœ¬çš„å¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿ä¸€ä¸ªURLçš„å¤±è´¥ä¸ä¼šå¯¼è‡´æ•´ä¸ªçˆ¬è™«åœæ­¢
    try:
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        with sync_playwright() as p:
            browser_type = getattr(p, options.get('browser', 'chromium'))
            browser = browser_type.launch(headless=not options.get('non_headless', False))
            context = browser.new_context(
                viewport={'width': options.get('width', 1280), 'height': options.get('height', 720)},
                user_agent=options.get('user_agent')
            )
            
            # åˆ›å»ºæ–°é¡µé¢
            page = context.new_page()
            
            # ç›‘å¬æ§åˆ¶å°æ¶ˆæ¯
            if options.get('log_console', False):
                page.on("console", lambda msg: logger.debug(f"æµè§ˆå™¨æ§åˆ¶å°: {msg.text}"))
            
            # è¯·æ±‚å’Œå“åº”æ‹¦æˆªå™¨ï¼Œç”¨äºæ”¶é›†ç½‘ç»œä¿¡æ¯
            request_start_times = {}
            response_data = {}
            
            page.on("request", lambda request: request_start_times.update({request.url: time.time()}))
            
            def handle_response(response):
                url = response.url
                if url in request_start_times:
                    response_time = time.time() - request_start_times[url]
                    status = response.status
                    # è®°å½•å“åº”ä¿¡æ¯
                    response_data[url] = {
                        'status': status,
                        'time': response_time,
                        'content_type': response.headers.get('content-type', '')
                    }
            
            page.on("response", handle_response)
            
            # è®¾ç½®è¶…æ—¶
            timeout = options.get('timeout', 30000)  # é»˜è®¤30ç§’
            
            # å¯¼èˆªåˆ°URL
            try:
                load_start = time.time()
                response = page.goto(url, timeout=timeout, wait_until=options.get('wait_until', 'networkidle'))
                load_time = time.time() - load_start
                
                # è·å–å“åº”çŠ¶æ€ç 
                status_code = response.status if response else None
                status_text = f"{status_code} {response.status_text}" if response else "æœªçŸ¥"
                
                # æ ¹æ®çŠ¶æ€ç è®¾ç½®é¢œè‰²
                if status_code and 200 <= status_code < 300:
                    status_color = f"{colorama.Fore.GREEN}âœ“ {status_text}{colorama.Style.RESET_ALL}"
                elif status_code and 300 <= status_code < 400:
                    status_color = f"{colorama.Fore.YELLOW}â†ª {status_text}{colorama.Style.RESET_ALL}"
                elif status_code and status_code >= 400:
                    status_color = f"{colorama.Fore.RED}âœ— {status_text}{colorama.Style.RESET_ALL}"
                else:
                    status_color = f"{colorama.Fore.MAGENTA}? çŠ¶æ€æœªçŸ¥{colorama.Style.RESET_ALL}"
                
                # è®°å½•çŠ¶æ€å’ŒåŠ è½½æ—¶é—´
                logger.info(f"{indent}  {status_color} åŠ è½½æ—¶é—´: {colorama.Fore.CYAN}{load_time:.2f}s{colorama.Style.RESET_ALL}")
                
                result['status_code'] = status_code
                result['status_text'] = response.status_text if response else "æœªçŸ¥"
                result['load_time'] = load_time
                result['content_type'] = response.headers.get('content-type', '') if response else ""
                
                # å¦‚æœæ˜¯é‡å®šå‘ï¼Œè®°å½•æœ€ç»ˆURL
                final_url = page.url
                if final_url != url:
                    result['redirected_to'] = final_url
                    redirect_display = truncate_url(final_url, max_length=80)
                    logger.info(f"{indent}  {colorama.Fore.YELLOW}â¤ é‡å®šå‘åˆ°: {redirect_display}{colorama.Style.RESET_ALL}")
                
                # ç­‰å¾…é¢å¤–æ—¶é—´
                extra_wait = options.get('extra_wait', 0)
                if extra_wait > 0:
                    page.wait_for_timeout(extra_wait)
                
                # æˆªå›¾
                screenshot_path = None
                if options.get('screenshots', True):
                    screenshot_dir = options.get('screenshot_dir', 'screenshots')
                    os.makedirs(screenshot_dir, exist_ok=True)
                    
                    # ä½¿ç”¨URLåˆ›å»ºæ–‡ä»¶å
                    safe_filename = re.sub(r'[^\w\-_.]', '_', url_key)[:200]
                    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
                    screenshot_filename = f"{safe_filename}_{timestamp}.png"
                    screenshot_path = os.path.join(screenshot_dir, screenshot_filename)
                    
                    # å…¨é¡µé¢æˆªå›¾
                    if options.get('full_page', False):
                        page.screenshot(path=screenshot_path, full_page=True)
                    else:
                        page.screenshot(path=screenshot_path)
                    
                    logger.info(f"{indent}  {colorama.Fore.BLUE}ğŸ“¸ æˆªå›¾ä¿å­˜åˆ°: {screenshot_path}{colorama.Style.RESET_ALL}")
                    result['screenshot'] = screenshot_path
                
                # è·å–é¡µé¢æ ‡é¢˜
                title = page.title()
                if title:
                    result['title'] = title
                    logger.info(f"{indent}  {colorama.Fore.WHITE}ğŸ“„ æ ‡é¢˜: {colorama.Fore.CYAN}\"{title}\"{colorama.Style.RESET_ALL}")
                
                # æ”¶é›†ç½‘ç»œç»Ÿè®¡ä¿¡æ¯
                result['resources'] = []
                for res_url, res_data in response_data.items():
                    result['resources'].append({
                        'url': res_url,
                        'status': res_data.get('status'),
                        'time': res_data.get('time'),
                        'content_type': res_data.get('content_type')
                    })
                
                # æ”¶é›†é¡µé¢ä¸Šçš„é“¾æ¥
                links = []
                if options.get('recursive', False) and level < options.get('max_depth', 1):
                    try:
                        # è·å–æ‰€æœ‰é“¾æ¥
                        link_elements = page.query_selector_all('a[href]')
                        domain = extract_domain(url)
                        
                        for element in link_elements:
                            href = element.get_attribute('href')
                            if href:
                                # å°è¯•æ„å»ºç»å¯¹URL
                                try:
                                    absolute_url = urljoin(url, href)
                                    link_domain = extract_domain(absolute_url)
                                    
                                    # æ ¹æ®é€‰é¡¹è¿‡æ»¤é“¾æ¥
                                    if options.get('same_domain', True) and link_domain != domain:
                                        continue
                                    
                                    # æ£€æŸ¥URLæ¨¡å¼
                                    url_pattern = options.get('url_pattern')
                                    if url_pattern and not re.search(url_pattern, absolute_url):
                                        continue
                                    
                                    links.append(absolute_url)
                                except Exception as e:
                                    logger.warning(f"è§£æé“¾æ¥å¤±è´¥: {href} - {str(e)}")
                        
                        logger.info(f"{indent}  {colorama.Fore.YELLOW}ğŸ”— å‘ç° {len(links)} ä¸ªé“¾æ¥{colorama.Style.RESET_ALL}")
                        
                    except Exception as e:
                        logger.error(f"æå–é“¾æ¥æ—¶å‡ºé”™: {str(e)}")
                
                # å…³é—­æµè§ˆå™¨
                browser.close()
                
                # é€’å½’å¤„ç†é“¾æ¥
                child_results = []
                if links and options.get('recursive', False) and level < options.get('max_depth', 1):
                    logger.info(f"{indent}  {colorama.Fore.CYAN}â–¼ å¼€å§‹å¤„ç†å­é“¾æ¥ ({len(links)}){colorama.Style.RESET_ALL}")
                    
                    # æ˜¾ç¤ºè¿›åº¦æ¡
                    with tqdm(total=len(links), desc=f"{indent}    é“¾æ¥è¿›åº¦", unit="é“¾æ¥", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]', disable=options.get('quiet', False)) as pbar:
                        for link in links:
                            child_result = process_url(link, options, visited_urls, level+1, url)
                            if child_result:
                                child_results.append(child_result)
                            pbar.update(1)
                    
                    logger.info(f"{indent}  {colorama.Fore.CYAN}â–² å­é“¾æ¥å¤„ç†å®Œæˆ{colorama.Style.RESET_ALL}")
                
                result['child_urls'] = child_results
                
            except TimeoutError:
                logger.error(f"{indent}  {colorama.Fore.RED}â± è¶…æ—¶: {url}{colorama.Style.RESET_ALL}")
                result['error'] = "é¡µé¢åŠ è½½è¶…æ—¶"
                browser.close()
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"{indent}  {colorama.Fore.RED}âŒ å¤„ç†URLæ—¶å‡ºé”™: {error_msg}{colorama.Style.RESET_ALL}")
        result['error'] = error_msg
    
    return result 